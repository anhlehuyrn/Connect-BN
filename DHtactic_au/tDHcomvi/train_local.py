import os
import torch
import torchvision
from torchvision import datasets, transforms, models
from torch import nn, optim
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix
import seaborn as sns

# --- Cáº¤U HÃŒNH ---
# TÃªn thÆ° má»¥c chá»©a áº£nh (náº±m cÃ¹ng cáº¥p vá»›i file code nÃ y)
DATA_DIR = 'tDHimg' 
BATCH_SIZE = 16 # Náº¿u mÃ¡y yáº¿u thÃ¬ giáº£m xuá»‘ng 8, mÃ¡y máº¡nh tÄƒng lÃªn 32
NUM_EPOCHS = 20
LEARNING_RATE = 0.001

def main():
    # 1. Kiá»ƒm tra thiáº¿t bá»‹
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸ Äang cháº¡y trÃªn: {device}")
    if device.type == 'cpu':
        print("âš ï¸ Cáº£nh bÃ¡o: Cháº¡y trÃªn CPU sáº½ cháº­m. Náº¿u mÃ¡y cÃ³ card rá»i NVIDIA, hÃ£y cÃ i PyTorch CUDA.")

    # 2. Kiá»ƒm tra dá»¯ liá»‡u
    if not os.path.exists(DATA_DIR):
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c '{DATA_DIR}'. HÃ£y kiá»ƒm tra láº¡i cáº¥u trÃºc thÆ° má»¥c!")
        return

    # 3. Chuáº©n bá»‹ Transform (Chuáº©n hÃ³a áº£nh)
    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                     std=[0.229, 0.224, 0.225])

    train_transform = transforms.Compose([
        transforms.RandomRotation(30),
        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
        transforms.ToTensor(),
        normalize
    ])

    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        normalize
    ])

    # 4. Load Dá»¯ liá»‡u & Chia táº­p Train/Val
    try:
        full_dataset = datasets.ImageFolder(root=DATA_DIR)
        classes = full_dataset.classes
        print(f"âœ… TÃ¬m tháº¥y {len(classes)} loáº¡i tranh: {classes}")
        
        # Chia 70% train - 30% val
        train_size = int(0.7 * len(full_dataset))
        val_size = len(full_dataset) - train_size
        train_dataset_raw, val_dataset_raw = torch.utils.data.random_split(full_dataset, [train_size, val_size])

        # Wrapper Ä‘á»ƒ Ã¡p dá»¥ng transform riÃªng
        class AppliedTransformDataset(Dataset):
            def __init__(self, subset, transform=None):
                self.subset = subset
                self.transform = transform
            def __getitem__(self, index):
                x, y = self.subset[index]
                if self.transform:
                    x = self.transform(x)
                return x, y
            def __len__(self):
                return len(self.subset)

        train_dataset = AppliedTransformDataset(train_dataset_raw, transform=train_transform)
        eval_dataset = AppliedTransformDataset(val_dataset_raw, transform=val_transform)

        # DataLoader (num_workers=0 Ä‘á»ƒ trÃ¡nh lá»—i trÃªn Windows)
        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
        eval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

    except Exception as e:
        print(f"âŒ Lá»—i load dá»¯ liá»‡u: {e}")
        return

    # 5. XÃ¢y dá»±ng Model ResNet18
    print("â³ Äang táº£i model ResNet18...")
    model = models.resnet18(pretrained=True)
    model.fc = nn.Linear(model.fc.in_features, len(classes))
    model = model.to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    # 6. Training Loop
    print(f"\nğŸš€ Báº¯t Ä‘áº§u Train trong {NUM_EPOCHS} epochs...")
    best_acc = 0.0
    history_loss = []
    history_acc = []

    for epoch in range(NUM_EPOCHS):
        model.train()
        running_loss = 0.0
        
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
        
        # ÄÃ¡nh giÃ¡ (Validation)
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in eval_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        epoch_loss = running_loss/len(train_loader)
        epoch_acc = 100 * correct / total
        history_loss.append(epoch_loss)
        history_acc.append(epoch_acc)

        print(f"Epoch {epoch+1}/{NUM_EPOCHS} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}%")

        # LÆ°u model tá»‘t nháº¥t
        if epoch_acc > best_acc:
            best_acc = epoch_acc
            torch.save(model.state_dict(), "best_dongho_model.pth")

    print(f"\nğŸ† HoÃ n táº¥t! Äá»™ chÃ­nh xÃ¡c cao nháº¥t: {best_acc:.2f}%")
    print("ğŸ’¾ ÄÃ£ lÆ°u model táº¡i: best_dongho_model.pth")

    # 7. Váº½ Confusion Matrix (PhiÃªn báº£n Ä‘Ã£ sá»­a lá»—i File Not Found)
    print("\nğŸ“Š Äang chuáº©n bá»‹ váº½ Confusion Matrix...")
    
    # Kiá»ƒm tra xem file model cÃ³ tá»“n táº¡i khÃ´ng
    if os.path.exists("best_dongho_model.pth"):
        print("âœ… ÄÃ£ tÃ¬m tháº¥y model tá»‘t nháº¥t, Ä‘ang load láº¡i...")
        model.load_state_dict(torch.load("best_dongho_model.pth"))
    else:
        print("âš ï¸ Cáº¢NH BÃO: KhÃ´ng tÃ¬m tháº¥y file 'best_dongho_model.pth'!")
        print("ğŸ‘‰ LÃ½ do cÃ³ thá»ƒ: QuÃ¡ trÃ¬nh train chÆ°a hoÃ n táº¥t hoáº·c khÃ´ng cÃ³ dá»¯ liá»‡u áº£nh.")
        print("ğŸ‘‰ Há»‡ thá»‘ng sáº½ sá»­ dá»¥ng model hiá»‡n táº¡i (Last Epoch) Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“ thay tháº¿.")
        
        # Náº¿u accuracy váº«n báº±ng 0 thÃ¬ dá»«ng luÃ´n
        if best_acc == 0.0:
            print("âŒ Lá»–I: Äá»™ chÃ­nh xÃ¡c báº±ng 0%. Vui lÃ²ng kiá»ƒm tra láº¡i thÆ° má»¥c 'tDHimg' xem cÃ³ áº£nh khÃ´ng!")
            return

    model.eval()
    
    all_preds = []
    all_labels = []

    print("ğŸ”„ Äang cháº¡y dá»± Ä‘oÃ¡n trÃªn táº­p kiá»ƒm thá»­...")
    with torch.no_grad():
        for inputs, labels in eval_loader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.numpy())
    
    # Chá»‰ váº½ náº¿u cÃ³ dá»¯ liá»‡u dá»± Ä‘oÃ¡n
    if len(all_labels) > 0:
        cm = confusion_matrix(all_labels, all_preds)
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='Blues')
        plt.xlabel('MÃ¡y Ä‘oÃ¡n (Predicted)')
        plt.ylabel('Thá»±c táº¿ (True)')
        plt.title('Confusion Matrix - PhÃ¢n loáº¡i Tranh ÄÃ´ng Há»“')
        plt.show()
        print("âœ… ÄÃ£ hiá»‡n biá»ƒu Ä‘á»“!")
    else:
        print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“ (Táº­p Validation trá»‘ng).")